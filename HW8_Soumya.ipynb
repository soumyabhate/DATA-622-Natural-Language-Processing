{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## DATA 622 Natural Language Processing\n",
        "### Homework 8"
      ],
      "metadata": {
        "id": "rZbn0WqnAuh-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Questions\n",
        "\n",
        "Use these two articles:\n",
        "url1 = \"https://www.nytimes.com/2024/05/14/climate/climate-change-extremeweather.html\"\n",
        "url2 = \"https://www.foxnews.com/science/climate-change-weather-impact-explained\"\n",
        "1. Based on AI/ML methods, measure the similarity between the two articles.\n",
        "2. Do they share\n",
        "a. Similar topics,\n",
        "b. Sentiment, and\n",
        "c. Emotions?\n",
        "3. Identify the top five keywords in each article.\n",
        "4. Summarize your findings using LLMs."
      ],
      "metadata": {
        "id": "cJFb3FCgBYxA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install only libs that don't need external downloads\n",
        "%pip install -qU \"requests==2.32.4\" beautifulsoup4 scikit-learn vaderSentiment"
      ],
      "metadata": {
        "id": "06MiayeId0fr"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re, textwrap, os, numpy as np, requests\n",
        "from bs4 import BeautifulSoup\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "URL_A = \"https://www.nasa.gov/climate-change/\"\n",
        "URL_B = \"https://www.foxnews.com/science\"\n",
        "\n",
        "def fetch(url: str) -> str:\n",
        "    r = requests.get(url, timeout=30); r.raise_for_status()\n",
        "    soup = BeautifulSoup(r.text, \"html.parser\")\n",
        "    for bad in soup([\"script\",\"style\",\"noscript\"]): bad.decompose()\n",
        "    text = \" \".join(soup.get_text(\" \").split())\n",
        "    return re.sub(r\"\\s+\",\" \", text).strip()\n",
        "\n",
        "def tfidf_cosine_and_keywords(a: str, b: str, k=5):\n",
        "    vec = TfidfVectorizer(stop_words=\"english\", ngram_range=(1,2), max_features=8000)\n",
        "    X = vec.fit_transform([a, b])\n",
        "    cos = float(cosine_similarity(X[0:1], X[1:2])[0][0])\n",
        "    idx2term = {i:t for t,i in vec.vocabulary_.items()}\n",
        "    def topk(row):\n",
        "        arr=row.toarray().ravel(); ii=np.argsort(arr)[::-1]\n",
        "        return [idx2term[i] for i in ii if arr[i]>0][:k]\n",
        "    return cos, topk(X[0:1]), topk(X[1:2])\n",
        "\n",
        "def summarize(text, max_sent=3):\n",
        "    sents = [s for s in re.split(r'(?<=[.!?])\\s+', text) if 20<=len(s)<=400]\n",
        "    if not sents: return \"\"\n",
        "    if len(sents) <= max_sent: return \" \".join(sents)\n",
        "    V = TfidfVectorizer(stop_words=\"english\", max_features=6000); S = V.fit_transform(sents)\n",
        "    score = (S.power(2).sum(axis=1)).A.ravel(); ix=np.argsort(score)[::-1][:max_sent]; ix.sort()\n",
        "    return \" \".join([sents[i] for i in ix])\n",
        "\n",
        "# -------------------- Fetch --------------------\n",
        "A, B = fetch(URL_A), fetch(URL_B)"
      ],
      "metadata": {
        "id": "SkNnhkGMfPxK"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- Q1: Similarity --------------------\n",
        "cos, kwA, kwB = tfidf_cosine_and_keywords(A, B, k=5)\n",
        "topic = \"High\" if cos>=.50 else \"Moderate\" if cos>=.25 else \"Low\"\n",
        "print(\"=\"*80)\n",
        "print(\"Q1) Similarity\")\n",
        "print(\"-\"*80)\n",
        "print(f\"Chars A: {len(A):,} | Chars B: {len(B):,}\")\n",
        "print(f\"Cosine similarity (TF-IDF 1–2 grams): {cos:.3f}\")\n",
        "print(f\"Topic overlap (heuristic): {topic}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWw0aI8hg3Eb",
        "outputId": "242b9b0c-57d7-40f3-c822-fd74883f6b28"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "Q1) Similarity\n",
            "--------------------------------------------------------------------------------\n",
            "Chars A: 13,050 | Chars B: 10,357\n",
            "Cosine similarity (TF-IDF 1–2 grams): 0.063\n",
            "Topic overlap (heuristic): Low\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- Q2: Sentiment --------------------\n",
        "SIA = SentimentIntensityAnalyzer()\n",
        "lab = lambda c: \"positive\" if c>.05 else \"negative\" if c<-.05 else \"neutral\"\n",
        "sA, sB = SIA.polarity_scores(A), SIA.polarity_scores(B)\n",
        "sA[\"label\"], sB[\"label\"] = lab(sA[\"compound\"]), lab(sB[\"compound\"])\n",
        "print(\"\\n\"+\"=\"*80)\n",
        "print(\"Q2) Sentiment\")\n",
        "print(\"-\"*80)\n",
        "print(f\"A: {sA['label']} (compound={sA['compound']:.3f})\")\n",
        "print(f\"B: {sB['label']} (compound={sB['compound']:.3f})\")\n",
        "print(\"Same label?\", \"Yes\" if sA[\"label\"]==sB[\"label\"] else \"No\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PVoauPeIg8Vr",
        "outputId": "3bad8c15-3c57-4564-9326-15bc5010226e"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "Q2) Sentiment\n",
            "--------------------------------------------------------------------------------\n",
            "A: positive (compound=0.998)\n",
            "B: negative (compound=-0.880)\n",
            "Same label? No\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- Q3: Keywords --------------------\n",
        "print(\"\\n\"+\"=\"*80)\n",
        "print(\"Q3) Top 5 keywords (per article)\")\n",
        "print(\"-\"*80)\n",
        "print(\"A:\", kwA)\n",
        "print(\"B:\", kwB)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4u6MNcbhAHm",
        "outputId": "ca7f25c7-1ac1-4c5b-fc86-704cd355ac32"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "Q3) Top 5 keywords (per article)\n",
            "--------------------------------------------------------------------------------\n",
            "A: ['nasa', 'read', 'article', 'min read', 'min']\n",
            "B: ['fox', 'fox news', 'deals', 'news', 'health']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- Q4: Summaries + report --------------------\n",
        "sumA, sumB = summarize(A,3), summarize(B,3)\n",
        "print(\"\\n\"+\"=\"*80)\n",
        "print(\"Q4) Summaries (≤3 sentences) + Consolidated findings\")\n",
        "print(\"-\"*80)\n",
        "print(\"A:\", textwrap.fill(sumA, 100))\n",
        "print(\"\\nB:\", textwrap.fill(sumB, 100))\n",
        "overall = (f\"Overall, cosine={cos:.3f} → {topic} topical overlap. \"\n",
        "           f\"Sentiment labels are {'the same' if sA['label']==sB['label'] else 'different'} \"\n",
        "           f\"({sA['label']} vs {sB['label']}).\")\n",
        "print(\"\\nConsolidated Findings:\")\n",
        "print(textwrap.fill(overall, 100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJviFR_1hHXZ",
        "outputId": "81c16fdb-e5c8-4abe-cadf-76b836a6dcd8"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "Q4) Summaries (≤3 sentences) + Consolidated findings\n",
            "--------------------------------------------------------------------------------\n",
            "A: article 1 month ago 6 min read Background article 1 month ago 3 min read What’s Up: October 2025\n",
            "Skywatching Tips from NASA article 1 month ago Highlights 4 min read Exoplanet Watch Overview\n",
            "article 1 month ago 6 min read Background article 1 month ago 5 min read Discovery Alert: ‘Baby’\n",
            "Planet Photographed in a Ring around a Star for the First Time! Read More Images of Change Before-\n",
            "and-after images of Earth. NASA Earth Exchange (NEX) NEX combines state-of-the-art supercomputing,\n",
            "Earth system modeling, and NASA remote sensing data feeds to deliver a work environment for\n",
            "exploring and analyzing terabyte- to petabyte-scale datasets covering large regions, continents or\n",
            "the globe.\n",
            "\n",
            "B: The Latest Science News Today | Fox News Fox News Media Fox News Media Fox Business Fox Nation Fox\n",
            "News Audio Fox Weather Outkick Fox Noticias Books Fox News U.S. All rights reserved. Quotes\n",
            "displayed in real-time or delayed by at least 15 minutes.\n",
            "\n",
            "Consolidated Findings:\n",
            "Overall, cosine=0.063 → Low topical overlap. Sentiment labels are different (positive vs negative).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NOTE - I have used other URLs reated to similar topics for both the given URLs as the given URL links were expired."
      ],
      "metadata": {
        "id": "d7kYlXowhPuj"
      }
    }
  ]
}